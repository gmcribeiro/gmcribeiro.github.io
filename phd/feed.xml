<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://goncalor00.github.io/phd/feed.xml" rel="self" type="application/atom+xml"/><link href="https://goncalor00.github.io/phd/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-03-09T01:17:23+00:00</updated><id>https://goncalor00.github.io/phd/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">ATOM experiments</title><link href="https://goncalor00.github.io/phd/reports/2024/atom_experiments/" rel="alternate" type="text/html" title="ATOM experiments"/><published>2024-04-03T16:40:16+00:00</published><updated>2024-04-03T16:40:16+00:00</updated><id>https://goncalor00.github.io/phd/reports/2024/atom_experiments</id><content type="html" xml:base="https://goncalor00.github.io/phd/reports/2024/atom_experiments/"><![CDATA[<p>I started the week by trying to clarify the roots of the problem that I’m trying to solve with Professor Rui Moreira. The issue is that MotionScope licenses aren’t available before Easter, so I’ll have to wait to explore the software and understand the problem. Meanwhile, I continued watching some online courses related to the basics of mechanical vibrations and machine learning and exploring the calibration of cameras.</p> <p>For camera calibration, I thought of finding a way to get the “ground truth” first to evaluate the quality of the camera calibration system that I will implement or develop. For that, I’ve been exploring <a href="https://github.com/lardemua/atom"><strong>ATOM</strong></a>, a set of calibration tools for robotic applications developed and maintained by teachers, researchers, and students of the University of Aveiro. This might be an overkill solution, but it is safer to use a tool that is well-understood by the LAR community. Thus, getting support is easier than using other available solutions or developing something from scratch.</p> <p>Since ATOM is a ROS-based application, it runs on Ubuntu 20.04, which is beginning to become outdated. I used Docker to install ATOM to avoid using an old Linux distro directly on my computer and to prevent future problems. This allows the use of ATOM in other operating systems, even Windows.</p> <p>The <a href="https://lardemua.github.io/atom_documentation/">ATOM documentation</a> provides examples (<a href="https://lardemua.github.io/atom_documentation/examples/">A</a>, <a href="https://github.com/lardemua/atom/tree/noetic-devel/atom_examples">B</a>), one of which is the use of <a href="https://github.com/lardemua/atom/tree/noetic-devel/atom_examples/rrbot">two RGB cameras</a>. There are also RGB-D examples that might be useful for João.</p> <div class="row mt-3" style="text-align: center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/phd/assets/posts/img/Screenshot_20240402_140350-480.webp 480w,/phd/assets/posts/img/Screenshot_20240402_140350-800.webp 800w,/phd/assets/posts/img/Screenshot_20240402_140350-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/phd/assets/posts/img/Screenshot_20240402_140350.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3" style="text-align: center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/phd/assets/posts/img/Screenshot_20240402_140637-480.webp 480w,/phd/assets/posts/img/Screenshot_20240402_140637-800.webp 800w,/phd/assets/posts/img/Screenshot_20240402_140637-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/phd/assets/posts/img/Screenshot_20240402_140637.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>In the <a href="https://doi.org/10.1016/j.eswa.2022.118000">ATOM paper</a>, some works related to the calibration of RGB cameras are mentioned. Some of these works are related to calibration without checkerboards (in the case of ATOM would be useful for online calibration) but “Patternless calibration approaches have the advantage of operating continuously if necessary, but loose in accuracy and robustness when compared to offline, one shot procedures. As such, offline calibrations are still the most commonly used.”. I will read those works to see how these calibrations are done.</p> <p>For the calibration of RGB cameras, ATOM detects the points using a pattern in both cameras—this is done for a set of “collections” (data from all sensors at the same time). Then, with a user guess for an approximated position and orientation of the cameras, it reprojects the pattern points. Then, it starts an optimization process to minimize the error between the points of the pattern and the reprojected points.</p>]]></content><author><name></name></author><category term="meeting-support"/><category term="meeting-preparation"/><category term="ATOM"/><category term="ROS"/><category term="Simulation"/><summary type="html"><![CDATA[Meeting report]]></summary></entry><entry><title type="html">First meeting</title><link href="https://goncalor00.github.io/phd/reports/2024/first-meeting/" rel="alternate" type="text/html" title="First meeting"/><published>2024-03-20T16:40:16+00:00</published><updated>2024-03-20T16:40:16+00:00</updated><id>https://goncalor00.github.io/phd/reports/2024/first-meeting</id><content type="html" xml:base="https://goncalor00.github.io/phd/reports/2024/first-meeting/"><![CDATA[<h1 id="support-material">Support material</h1> <p><a href="/phd/">Goals</a> and <a href="/phd/timeline/">Tasks</a></p> <h1 id="meeting-report">Meeting report</h1> <p>I need to define better the problem description:</p> <ul> <li>Learn how the MotionScope works</li> <li>What is possible to do with the MotionScope, and what do we want to do that isn’t currently possible?</li> </ul> <p>After a better understanding, I should talk again with prof. Rui Moreira, in order to adjust the “final” problem description and planning</p> <p>Next LAR Meeting: 11/04/2024 (5, 10, or 15 minutes???)</p> <h1 id="next-meeting-03042024-1030">Next meeting (03/04/2024 10:30)</h1> <p>Finnish the problem description and planification</p> <p><a href="/phd/">Goals</a> and <a href="/phd/timeline/">Tasks</a></p>]]></content><author><name></name></author><category term="meeting-report"/><category term="MotionScope"/><category term="Research"/><summary type="html"><![CDATA[Meeting report]]></summary></entry></feed>