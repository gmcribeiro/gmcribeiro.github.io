<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> First research on 3D motion magnification | Gonçalo Ribeiro </title> <meta name="author" content="Gonçalo Ribeiro"> <meta name="description" content="Meeting preparation and support"> <meta name="keywords" content="Computer vision, Vibrations, 3D reconstructions, 2D and 3D Motion magnification, Camera calibration"> <link rel="stylesheet" href="/phd/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/phd/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/phd/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/phd/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%93%89&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/phd/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://goncalor00.github.io/phd/reports/2024/first_research_3d_motion_magnification/"> <script src="/phd/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/phd/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/phd/"> <span class="font-weight-bold">Gonçalo</span> Ribeiro </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/phd/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/phd/reports/index.html">Reports </a> </li> <li class="nav-item "> <a class="nav-link" href="/phd/timeline/">Timeline </a> </li> <li class="nav-item "> <a class="nav-link" href="/phd/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/phd/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/phd/repositories/">Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/phd/sota/">SOTA </a> </li> <li class="nav-item "> <a class="nav-link" href="/phd/courses/">Courses </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search (ctrl + k)" onclick="openSearchModal()"> <span class="nav-link">Search <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">First research on 3D motion magnification</h1> <p class="post-meta"> Created in November 25, 2024 </p> <p class="post-tags"> <i class="fa-solid fa-calendar fa-sm"></i> 2024   ·   <i class="fa-solid fa-hashtag fa-sm"></i> Computer Vision   <i class="fa-solid fa-hashtag fa-sm"></i> Motion magnification   <i class="fa-solid fa-hashtag fa-sm"></i> 3D Motion magnification   <i class="fa-solid fa-hashtag fa-sm"></i> Research   ·   <i class="fa-solid fa-tag fa-sm"></i> meeting-support   <i class="fa-solid fa-tag fa-sm"></i> meeting-preparation </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Works on 3D motion magnification</p> <p><a href="https://3d-motion-magnification.github.io/" rel="external nofollow noopener" target="_blank">3D Motion Magnification: Visualizing Subtle Motions with Time-Varying Neural Fields</a></p> <div class="col-sm mt-3 mt-md-0" style="text-align: center"> <figure> <video src="/phd/assets/posts/vid/11_2024/fork_3.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls=""></video> </figure> </div> <p>This approach is based on <a href="https://www.matthewtancik.com/nerf" rel="external nofollow noopener" target="_blank">NeRF</a> and already supports the use of a single-camera</p> <p>Research gaps:</p> <ul> <li>NeRF requires lots of viewpoints.</li> <li>NeRF is computationally heavy - I can only use pre-trained weights on the author’s examples since the laptop doesn’t have enough graphical memory. The compute time is around 30 seconds per frame, even at the inference stage.</li> <li>NeRF needs the camera pose and orientation for each image in the training stage. Some authors use the <a href="https://colmap.github.io/" rel="external nofollow noopener" target="_blank">COLMAP</a> tool to retrieve this information from the images. (COLMAP works similarly to the method I used to retrieve the camera’s pose). The authors of <a href="https://3d-motion-magnification.github.io/" rel="external nofollow noopener" target="_blank">3D Motion Magnification: Visualizing Subtle Motions with Time-Varying Neural Fields</a> claim that, for real-world environments, the accuracy of these methods may not be enough for motion magnification since “inaccurate pose estimation would exacerbate the ambiguity between camera motion and scene motion, which could hinder magnifying subtle scene motions or lead to false motion magnification. Therefore, real-world data should be captured under conditions where accurate camera intrinsic and extrinsic parameters are accessible, either from reliable RGB-based SfM with textured surfaces in the scene, or from cameras that support 6-DoF tracking during capture”. Since MotionScope does the motion magnification in 2D, the methodology would be different by avoiding the motion magnification on the fly, which may allow less accuracy.</li> </ul> <p>The following methods don´t have a 3D graphical representation of the motion magnification. They present quantitative displacement results on convenient points (where it is possible to match the points between two viewpoints with reliability). All of them require camera calibration.</p> <p><a href="https://doi.org/10.1016/j.jsv.2017.06.003" rel="external nofollow noopener" target="_blank">Feasibility of extracting operating shapes using phase-based motion magnification technique and stereo-photogrammetry</a></p> <ul> <li>Improvement of the data quality</li> <li>3D information</li> </ul> <p><a href="https://doi.org/10.1016/j.ymssp.2018.02.006" rel="external nofollow noopener" target="_blank">3D mode shapes characterisation using phase-based motion magnification in large structures using stereoscopic DIC</a></p> <ul> <li>Reduction of noise, allowing the capture of low-amplitude displacements</li> </ul> <p><a href="https://doi.org/10.1016/j.jsv.2022.117244" rel="external nofollow noopener" target="_blank">Target-free 3D tiny structural vibration measurement based on deep learning and motion magnification</a></p> <ul> <li>This method uses the Super Glue feature match algorithm to find the matches and then triangulate to get the 3D displacement.</li> </ul> <p>Research gaps:</p> <ul> <li>Uncalibrated cameras</li> <li>Interactive results presentation - The idea is to generate a mesh/point cloud that we can observe from any perspective</li> </ul> <p>Possible review paper title: The use of multi-view systems on phase-based motion magnification</p> <p>Deliverables for the immersive week:</p> <style>.pdf-embed-wrap-f1ebaf9f-b604-43f1-861b-645904c0bd86{display:flex;flex-direction:column;width:100%;height:650px}.pdf-embed-container-f1ebaf9f-b604-43f1-861b-645904c0bd86{height:100%}.pdf-link-f1ebaf9f-b604-43f1-861b-645904c0bd86{background-color:white;text-align:center;border-style:solid}.pdf-embed-container-f1ebaf9f-b604-43f1-861b-645904c0bd86 iframe{width:100%;height:100%}</style> <div class="pdf-embed-wrap-f1ebaf9f-b604-43f1-861b-645904c0bd86"> <div class="pdf-link-f1ebaf9f-b604-43f1-861b-645904c0bd86"> <a href="/phd/assets/posts/pdf/11_2024/1_imersive_week.pdf" target="_blank">View PDF</a> </div> <div class="pdf-embed-container-f1ebaf9f-b604-43f1-861b-645904c0bd86"> <iframe src="/phd/assets/posts/pdf/11_2024/1_imersive_week.pdf" frameborder="0" allowfullscreen=""></iframe> </div> </div> <p><br></p> <p>Research Questions:</p> <ul> <li>Is it more effective to combine multiple viewpoints to compute 3D motion magnification directly, or to first compute 2D motion magnification for each viewpoint and then combine them for 3D motion magnification?</li> <li>Does the latter approach reduce the need for highly accurate calibration?</li> <li>Can a single moving camera, synchronized across viewpoints, replace the use of multiple cameras for 3D motion magnification?</li> <li>Is it possible to perform 3D reconstruction using only a small number of viewpoints and without pre-calibrating the cameras?</li> <li>Is there a more effective way to present the results of 3D motion magnification?</li> </ul> <p>Contributions:</p> <ul> <li>Improved Methodology for 3D Motion Magnification: By reducing calibration requirements, making the process more practical and accessible, and by using a single moving camera instead of multiple cameras, which could lower costs and simplify experimental setups.</li> <li>Efficient 3D Reconstruction with Minimal Viewpoints: By developing methods for accurate 3D reconstruction using fewer viewpoints, reducing hardware requirements and computational complexity, and exploring the potential to bypass pre-calibration, which could streamline the workflow and make the technology more user-friendly.</li> <li>Enhanced Visualization of Results: By proposing new ways to display 3D motion magnification results, such as interactive 3D meshes or point clouds, which could offer better insights and flexibility compared to traditional video-based outputs.</li> </ul> <p>Para a sincronização podiam ser geradas mais imagens para completar o ciclo de vibração e garantir que os pontos estão no mesmo sitio em todos os pontos de vista, ajudando também na reconstrução 3D continua - combate o problema da subamostragem;</p> <p>Perceber o trabalho por de trás do motion scope para perceber o que é que pode estar a faltar e replicar a metodologia do motion scope para conseguir sincronizar pontos de vista; Se não resolver tentar geração interpolada de imagens</p> <p>Uma ideia - uma rede que crie um frame entre dois seguidos e depois chamar iterativamente</p> <p>recusrive generative network</p> <p>O que dar a rede?</p> <p>Interpolation of sub-sampling (…) - começar por sinais e dps ir para coisas mais complexa</p> <p>Tentar arranjar um simulador de vibrações para conseguir arranjar um ground truth - esta pode ser a primeira contribuição ao dar para sintetizar imagens</p> <p><strong>Suma: Simulador; interpolação de imagens; 3D motion magnification</strong></p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/phd/reports/2025/simulating_motion_magnification/">Simulating 2D motion magnification</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/phd/reports/2025/review_article_mie/">Review articles for MIE</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/phd/reports/2024/ideas_review_paper/">Ideas for the research paper</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/phd/reports/2024/3d_lightglue/">LightGlue on 3D reconstruction</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/phd/reports/2024/testing_lightglue/">Testing LightGlue</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Gonçalo Ribeiro. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/phd/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/phd/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/phd/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/phd/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/phd/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/phd/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/phd/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/phd/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/phd/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/phd/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/phd/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/phd/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/phd/assets/js/search-data.js"></script> <script src="/phd/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>