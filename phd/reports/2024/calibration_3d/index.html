<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> First steps on 3D reconstruction | Gonçalo Ribeiro </title> <meta name="author" content="Gonçalo Ribeiro"> <meta name="description" content="Meeting preparation and support"> <meta name="keywords" content="Computer vision, Vibrations, 3D reconstructions, 2D and 3D Motion magnification, Camera calibration"> <link rel="stylesheet" href="/phd/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/phd/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/phd/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/phd/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%93%89&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/phd/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://goncalor00.github.io/phd/reports/2024/calibration_3d/"> <script src="/phd/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/phd/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/phd/"> <span class="font-weight-bold">Gonçalo</span> Ribeiro </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/phd/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/phd/reports/index.html">Reports </a> </li> <li class="nav-item "> <a class="nav-link" href="/phd/timeline/">Timeline </a> </li> <li class="nav-item "> <a class="nav-link" href="/phd/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/phd/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/phd/repositories/">Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/phd/sota/">SOTA </a> </li> <li class="nav-item "> <a class="nav-link" href="/phd/courses/">Courses </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search (ctrl + k)" onclick="openSearchModal()"> <span class="nav-link">Search <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">First steps on 3D reconstruction</h1> <p class="post-meta"> Created in May 24, 2024 </p> <p class="post-tags"> <i class="fa-solid fa-calendar fa-sm"></i> 2024   ·   <i class="fa-solid fa-hashtag fa-sm"></i> Computer Vision   <i class="fa-solid fa-hashtag fa-sm"></i> Feature Matching   <i class="fa-solid fa-hashtag fa-sm"></i> 3D Reconstruction   <i class="fa-solid fa-hashtag fa-sm"></i> Calibration   ·   <i class="fa-solid fa-tag fa-sm"></i> meeting-support   <i class="fa-solid fa-tag fa-sm"></i> meeting-preparation </p> </header> <article class="post-content"> <div id="markdown-content"> <p>I started by trying to build an entire pipeline to see the end results of the 3D points. This way it is easier to see if something is going wrong in one of the steps.</p> <p>I tried to retrieve the intrinsic parameters of my smartphone’s camera from the image’s metadata, but I was getting weird results. Then I tried to get them manually, but someone in the lab reminded me that smartphones have auto-focus and the parameters change. To avoid messing with my phone, I simply used another camera that was available and not being used by anyone in the lab (an Orbbec Astra Pro) and got the intrinsic parameters using a chessboard and a ROS tool</p> <div class="row mt-3" style="text-align: center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/phd/assets/posts/img/05_2024/Screenshot_20240424_162653-480.webp 480w,/phd/assets/posts/img/05_2024/Screenshot_20240424_162653-800.webp 800w,/phd/assets/posts/img/05_2024/Screenshot_20240424_162653-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/phd/assets/posts/img/05_2024/Screenshot_20240424_162653.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>I used SIFT once more to get the matching points from two viewpoints:</p> <div class="row mt-3" style="text-align: center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/phd/assets/posts/img/05_2024/Linked%20Points-480.webp 480w,/phd/assets/posts/img/05_2024/Linked%20Points-800.webp 800w,/phd/assets/posts/img/05_2024/Linked%20Points-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/phd/assets/posts/img/05_2024/Linked%20Points.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Then, found the Essential matrix → Rotation and Translation → Projection matrices</p> <p>With the matching points and projection matrices, I triangulated and plotted the points (ignoring the distortion parameters) and got this:</p> <div class="col-sm mt-3 mt-md-0" style="text-align: center"> <figure> <video src="/phd/assets/posts/vid/05_2024/3D%20plots.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls=""></video> </figure> </div> <p>But the Essential matrix is defined only up to scale (in the illustration it is the fundamental matrix, but the essential matrix comes from the fundamental matrix knowing the intrinsic parameters).</p> <div class="col-sm mt-3 mt-md-0" style="text-align: center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/phd/assets/posts/img/05_2024/Screenshot_20240425_154214(1)-480.webp 480w,/phd/assets/posts/img/05_2024/Screenshot_20240425_154214(1)-800.webp 800w,/phd/assets/posts/img/05_2024/Screenshot_20240425_154214(1)-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/phd/assets/posts/img/05_2024/Screenshot_20240425_154214(1).png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption"> Source: <a href="https://www.youtube.com/watch?v=izpYAwJ0Hlw&amp;list=PL2zRqk16wsdoCCLpou-dGo7QQNks1Ppzo&amp;index=10" rel="external nofollow noopener" target="_blank">https://www.youtube.com/watch?v=izpYAwJ0Hlw&amp;list=PL2zRqk16wsdoCCLpou-dGo7QQNks1Ppzo&amp;index=10</a> </div> <p>OpenCV has a function that solves this by setting the distance between cameras to 1, which means that the distance between points is relative to the distance between cameras. We can retrieve the real scale factor by having an object in the image of known dimensions.</p> <p>Using the distortion factors, I got weird results and I haven’t found out yet what I did wrong:</p> <div class="col-sm mt-3 mt-md-0" style="text-align: center"> <figure> <video src="/phd/assets/posts/vid/05_2024/3DPlotdistort.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls=""></video> </figure> </div> <p>Re-calibrating the camera with more images and still ignoring the distortion parameters, the results are apparently better</p> <div class="col-sm mt-3 mt-md-0" style="text-align: center"> <figure> <video src="/phd/assets/posts/vid/05_2024/teste.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls=""></video> </figure> </div> <p>Then I experimented with bending the paper like this:</p> <div class="col-sm mt-3 mt-md-0" style="text-align: center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/phd/assets/posts/img/05_2024/img0_perpendicular-480.webp 480w,/phd/assets/posts/img/05_2024/img0_perpendicular-800.webp 800w,/phd/assets/posts/img/05_2024/img0_perpendicular-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/phd/assets/posts/img/05_2024/img0_perpendicular.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>With SIFT I got this:</p> <div class="col-sm mt-3 mt-md-0" style="text-align: center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/phd/assets/posts/img/05_2024/linked_pointsv2-480.webp 480w,/phd/assets/posts/img/05_2024/linked_pointsv2-800.webp 800w,/phd/assets/posts/img/05_2024/linked_pointsv2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/phd/assets/posts/img/05_2024/linked_pointsv2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>And plotting, I got this:</p> <div class="col-sm mt-3 mt-md-0" style="text-align: center"> <figure> <video src="/phd/assets/posts/vid/05_2024/bend.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls=""></video> </figure> </div> <p>This result gave me more confidence about the reliability of the previous steps.</p> <p>Then, I started working on a 3D reconstruction of the object. I started by trying some OpenCV functions. The functions that I found create disparity maps, and the goal was to create a 3D plot from those maps. With this approach, I only got bad results without any meaning, and I gave up.</p> <p>Using the two images from the two viewpoints and doing the dot product between the fundamental matrix and the coordinates of the pixel in analyses in the first image, the result is a vector containing the $a$, $b$, and $c$ parameters of the epipolar line ($ax + by + c = 0$) in the second image:</p> <div class="col-sm mt-3 mt-md-0" style="text-align: center"> <figure> <video src="/phd/assets/posts/vid/05_2024/2024-05-2215-44-12-ezgif.com-video-to-mp4-converter.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls=""></video> </figure> </div> <p>Inside the epipolar line will be the point of image 2 that matches the point in analyses of image 1. This reduces the search of the matching point by a lot, being a 1D search instead of a 2D search.</p> <p>Although the search is less than without the epipolar line, there are many points, and even using the simplest algorithm possible to compare the windows of pixels (absolute distance between arrays—cv2.norm()) from the two images, the time of execution using Python is more than 10 minutes.</p> <div class="col-sm mt-3 mt-md-0" style="text-align: center"> <figure> <video src="/phd/assets/posts/vid/05_2024/2024-05-2314-59-48-ezgif.com-video-to-mp4-converter.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls=""></video> </figure> </div> <p>The cv2.norm() is not ideal for this use case and generates a lot of errors, but by removing isolated points, I got this:</p> <div class="col-sm mt-3 mt-md-0" style="text-align: center"> <figure> <video src="/phd/assets/posts/vid/05_2024/point_cloud.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls=""></video> </figure> </div> <p>After that, I decided to try to optimize the code, but I only got minor improvements. So, I took a C++ course and implemented the slowest function in C++. The major part of the program is written in Python, and the function with high computation cost is written in C++ and compiled. With this, the computation time of the function is less than 30 seconds, more than 30x faster than Python.</p> <div class="col-sm mt-3 mt-md-0" style="text-align: center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/phd/assets/posts/img/05_2024/Screenshot_20240522_151420-480.webp 480w,/phd/assets/posts/img/05_2024/Screenshot_20240522_151420-800.webp 800w,/phd/assets/posts/img/05_2024/Screenshot_20240522_151420-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/phd/assets/posts/img/05_2024/Screenshot_20240522_151420.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0" style="text-align: center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/phd/assets/posts/img/05_2024/Screenshot_20240523_191350-480.webp 480w,/phd/assets/posts/img/05_2024/Screenshot_20240523_191350-800.webp 800w,/phd/assets/posts/img/05_2024/Screenshot_20240523_191350-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/phd/assets/posts/img/05_2024/Screenshot_20240523_191350.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>The current pipeline looks like this:</p> <div class="col-sm mt-3 mt-md-0" style="text-align: center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/phd/assets/posts/img/05_2024/pointcloud_explained.svg" sizes="95vw"></source> <img src="/phd/assets/posts/img/05_2024/pointcloud_explained.svg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>Unanswered questions:</p> <ul> <li>What are the best algorithms (green boxes) for the current pipeline?</li> <li>How can I evaluate the quality of the results?</li> <li>How can I estimate the intrinsic parameters after changing the focal length?</li> <li>In a stream of images (after motion scope), should I rerun the current pipeline each time, or should I use some kind of tracking algorithm?</li> </ul> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/phd/reports/2025/review_article_mie/">Review articles for MIE</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/phd/reports/2024/ideas_review_paper/">Ideas for the research paper</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/phd/reports/2024/first_research_3d_motion_magnification/">First research on 3D motion magnification</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/phd/reports/2024/3d_lightglue/">LightGlue on 3D reconstruction</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/phd/reports/2024/testing_lightglue/">Testing LightGlue</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Gonçalo Ribeiro. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/phd/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/phd/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/phd/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/phd/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/phd/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/phd/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/phd/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/phd/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/phd/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/phd/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/phd/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/phd/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/phd/assets/js/search-data.js"></script> <script src="/phd/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>